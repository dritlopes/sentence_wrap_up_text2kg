# Triplet generation and eye movements in reading

This repo contains the code for analysing the relation between contextual information and eye movements in reading. Contextual information processing is approximated by the formation of _triplets_ (entities and relations between entities) as we go through text. 

To generate triplets from text, we run the *Relik* model in a continuous-incremental manner and store triple additions, deletions and full outputs after **every word** in the text.

* Model source: <https://github.com/SapienzaNLP/relik>  
* Corpus sources: [MECO](https://osf.io/srdhm) and [OneStop](https://osf.io/2prdq/)
* VU **BAZIS** HPC: <https://vu.nl/en/research/portal/research-impact-support-portal/high-performance-research-computing>

---

## Repository layout

| Path / file                            | What it holds                                                                                                                                    |
|----------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| **data/output**                        | Final CSVs with eye movement data and triplets generation info per word (e.g. triplets generated, number of triplets)                            |
| **data/processed**                     | Processed eye movement data from corpora MECO and OneStop.                                                                                       |
| **src/process_corpus.py**              | Code that process the eye movement data files from MECO and OneStop corpora. Python file that produces the step-level JSON files                 |
| **src/extract_triplets.py**            | Code that runs the text-to-triplets model (Relik) on the texts from the eye movement corpora                                                     |
| **src/relik_test_batch.sh**            | Bash script that queues `extract_triplets.py` on the BAZIS cluster                                                                               |
| **src/compile_output.py**              | Code that converts the json outputs from the relik model into a csv, and merges the relik output with the eye movement data for further analysis |
| **src/plots.py**                       | Code for generating plots to visualise the data                                                                                                  |
| **src/stats_analysis_<corpus_name>.R** | Code for running the analysis reported in the paper                                                                                              |

---

## Output file-naming pattern
1. When running the script `extract_triplets.py`, a json file is generated per word in each text, with the triplets generated by the model up to each word. 
This step output filename follows the format `output_step_<word_position_in_text>_<model>_<corpus>_<text_identifier>_<model_threshold>_<model_window_size>.json`
* **word_position_in_text** is the output step number which is equivalent to until where in the text (word-wise) the input of the model goes. 
* **model** is the name of the relik model implementation in HuggingFace (e.g. `relik-cie-small`, `relik-cie-large`, `relik-cie-xl`).
* **corpus** is the name of the eye movement corpus (`meco` or `onestop`).
* **text_identifier** is a unique code that identifies each text of the corpus. For OneStop, the identifier has the format 
`<article_bath-article_id-paragraph_id-difficulty_level>`. For MECO, the identifier has the format `<most_frequent_proper_noun_in_text>`.
* **model_threshold** is the score threshold for a triplet to be considered sufficiently recognized in the input.
* **model_window_size** is the number of characters in the input to be processed as one chunk by the text-to-triplet model (Relik).

2. When running the script `compile_output.py`, three csv files are generated per text. The filename follows the format 
`<type_of_output>_<model>_<corpus>_<text_identifier>.csv`
* **type of output** is the type of output, which can `additions` (only the steps (word positions) in which new triplets were added to the output), 
`deletions` (only steps (word positions) in which triplets were removed from the output) or `full` (all output steps).
Example: `additions_relik-cie-large_meco_beekeeping.csv`

## How the output CSV looks like

The CSVs produced by `compile_output.py`, before merging with eye movement data:

| Column                               | Meaning                                                     |
|--------------------------------------|-------------------------------------------------------------|
| `text_type` if corpus MECO           | Keyword for the corpus text                                 |
| `article_batch` if corpus OneStop    | Batch of article paragraph belongs to                       |
| `article_id` if corpus OneStop       | ID of article paragraph belongs to                          |
| `paragraph_id` if corpus OneStop     | ID of paragraph                                             |
| `difficulty_level` if corpus OneStop | readability version of the article the paragraph belongs to |
| `output_step`                        | Word index                                                  |
| `current_word`                       | The word that triggered this output                         |
| `current_text`                       | Full text up to `current_word`                              |
| `new_triplets`                       | Triples just added at this step (JSON list)                 |
| `total_triplets`                     | Complete triple set present after this step                 |
| `triplet_scores`                     | Relik scores for `new_triplets`                             |

The CSV produced by `compile_output.py` after merging with eye movement data contains the variables in the processed eye movement data plus the following variables:

| Column            | Meaning                              |
|-------------------|--------------------------------------|
| `total_triplets`  | The generated triplets               |
| `triplet_scores`  | The scores of the generated triplets |
| `n_triplets`      | The number of triplets generated     |
| `sum_scores`      | The sum of the triplet scores        |

---

## References

Berzak, Y., Malmaud, J., Shubi, O., Meiri, Y., Lion, E., & Levy, R. (2025). Onestop: A 360-participant english eye-tracking dataset with different reading regimes. PsyArXiv preprint.
Siegelman, N., Schroeder, S., Acart√ºrk, C., Ahn, H. D., Alexeeva, S., Amenta, S., ... & Kuperman, V. (2022). Expanding horizons of cross-linguistic research on reading: The Multilingual Eye-movement Corpus (MECO). Behavior research methods, 54(6), 2843-2863.

## Acknowledgements

Big thanks to the Research Assistants [Konstantin Mihhailov](https://github.com/ElectricBoogaloo6) and [Haomin Wu](https://github.com/returnhw99), for conducting hyperparameter searching with Relik, and helping to set up the analysis, respectively.